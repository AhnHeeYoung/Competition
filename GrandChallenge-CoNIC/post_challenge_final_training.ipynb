{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "005da1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "\n",
    "from skimage import draw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from cv2 import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "\n",
    "import tifffile as tiff\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "# import openslide\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import memmap\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from skimage import morphology as morph\n",
    "\n",
    "import skimage\n",
    "from skimage.color import rgb2gray, rgb2hed, hed2rgb, rgb2hsv, hsv2rgb\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.util import dtype\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import logging\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from SwinUnet.networks.vision_transformer import SwinUnet as ViT_seg\n",
    "\n",
    "from scipy.ndimage import measurements\n",
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from metrics.stats_utils import get_pq, get_multi_pq_info, get_multi_r2\n",
    "\n",
    "from scipy.ndimage import filters, measurements\n",
    "from scipy.ndimage.morphology import (\n",
    "    binary_dilation,\n",
    "    binary_fill_holes,\n",
    "    distance_transform_cdt,\n",
    "    distance_transform_edt,\n",
    ")\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "import sys\n",
    "# sys.path.append('segmenter/')\n",
    "\n",
    "# from segmenter.segm.model.factory import create_segmenter\n",
    "\n",
    "\n",
    "from my_misc import *\n",
    "from my_misc import __proc_np_hv\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "def process_segmentation(output_binary, output_hv, output_classification):\n",
    "\n",
    "    np_map = torch.softmax(output_binary, 1)[0].cpu().detach().permute(1, 2, 0)[..., 1].unsqueeze(2).numpy()\n",
    "    np_map = cv2.resize(np_map.astype('float32'), (0, 0), fx=2.0, fy=2.0)\n",
    "\n",
    "    hv_map = output_hv[0].cpu().detach().permute(1, 2, 0).numpy().astype('float32')\n",
    "    hv_map = cv2.resize(hv_map, (0, 0), fx=2.0, fy=2.0) \n",
    "\n",
    "    tp_map = torch.argmax(torch.softmax(output_classification, 1), 1).cpu().numpy()[0]\n",
    "    tp_map = cv2.resize(tp_map, (0, 0), fx=2.0, fy=2.0, interpolation=cv2.INTER_NEAREST).astype('float32')\n",
    "\n",
    "    inst_map = __proc_np_hv(np_map[..., None], hv_map)\n",
    "    inst_dict = get_instance_info(inst_map, tp_map)\n",
    "\n",
    "    type_map = np.zeros_like(inst_map)\n",
    "    inst_type_colours = np.array([\n",
    "        [v['type']] * 3 for v in inst_dict.values()\n",
    "    ])\n",
    "    type_map = overlay_prediction_contours(\n",
    "        type_map, inst_dict,\n",
    "        line_thickness=-1,\n",
    "        inst_colours=inst_type_colours)\n",
    "\n",
    "    pred_map = np.dstack([inst_map, type_map])\n",
    "\n",
    "    pred_map = cv2.resize(pred_map, (0, 0), fx=0.5, fy=0.5, interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    return pred_map\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_segmentation_2branch(output_binary, output_classification):\n",
    "\n",
    "    tp_map = torch.argmax(torch.softmax(output_classification, 1), 1).cpu().numpy()[0]\n",
    "\n",
    "    temp = torch.argmax(torch.softmax(output_binary, 1), 1).cpu()[0]\n",
    "    inst_map = measurements.label(temp)[0]\n",
    "    inst_map = remove_small_objects(inst_map, 10)\n",
    "    \n",
    "    inst_dict = get_instance_info(inst_map, tp_map)\n",
    "\n",
    "    type_map = np.zeros_like(inst_map)\n",
    "    inst_type_colours = np.array([\n",
    "        [v['type']] * 3 for v in inst_dict.values()\n",
    "    ])\n",
    "    type_map = overlay_prediction_contours(\n",
    "        type_map, inst_dict,\n",
    "        line_thickness=-1,\n",
    "        inst_colours=inst_type_colours)\n",
    "\n",
    "    pred_map = np.dstack([inst_map, type_map])\n",
    "\n",
    "    \n",
    "    return pred_map\n",
    "\n",
    "\n",
    "\n",
    "class ConicDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_path, mask_path, counts, source, transform, copypaste, copy_level):\n",
    "\n",
    "        self.image_path = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.counts = counts\n",
    "        self.source = source\n",
    "\n",
    "        self.transform = transform\n",
    "        self.copypaste = copypaste\n",
    "        self.copy_level = copy_level\n",
    "        \n",
    "        \n",
    "#         with open('insufficient_class_alldict/insufficient_class_alldict.pickle','rb') as temp:\n",
    "#             self.insufficient_class_alldict = pickle.load(temp)  \n",
    "        \n",
    "#         with open('insufficient_class_alldict/insufficient_class_alldict_consep.pickle','rb') as temp:\n",
    "#             self.insufficient_class_alldict_consep = pickle.load(temp)      \n",
    "            \n",
    "#         with open('insufficient_class_alldict/insufficient_class_alldict_crag.pickle','rb') as temp:\n",
    "#             self.insufficient_class_alldict_crag = pickle.load(temp) \n",
    "            \n",
    "#         with open('insufficient_class_alldict/insufficient_class_alldict_dpath.pickle','rb') as temp:\n",
    "#             self.insufficient_class_alldict_dpath = pickle.load(temp) \n",
    "            \n",
    "#         with open('insufficient_class_alldict/insufficient_class_alldict_glas.pickle','rb') as temp:\n",
    "#             self.insufficient_class_alldict_glas = pickle.load(temp)       \n",
    "            \n",
    "#         with open('insufficient_class_alldict/insufficient_class_alldict_pannuke.pickle','rb') as temp:\n",
    "#             self.insufficient_class_alldict_pannuke = pickle.load(temp)             \n",
    "            \n",
    "   \n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.image_path))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = self.image_path[idx].astype('uint8')\n",
    "        original = image.copy()\n",
    "\n",
    "        mask = self.mask_path[idx]\n",
    "        \n",
    "        mask_instance = mask[..., 0]\n",
    "        mask_class = mask[..., 1]\n",
    "        mask_class_original = mask_class.copy()\n",
    "        \n",
    "#         counts = self.counts[idx]\n",
    "#         source = self.source[idx]\n",
    "        \n",
    "#         default   \n",
    "        class1_rate = 0.3\n",
    "        class2_rate = 0.1\n",
    "        class3_rate = 0.05\n",
    "        class4_rate = 0.15\n",
    "        class5_rate = 0.3\n",
    "        class6_rate = 0.1\n",
    "\n",
    "#         class1_rate = 0.4\n",
    "#         class2_rate = 0\n",
    "#         class3_rate = 0\n",
    "#         class4_rate = 0.2\n",
    "#         class5_rate = 0.4\n",
    "#         class6_rate = 0\n",
    "        \n",
    "        resize_rate = 0\n",
    "        \n",
    "        self.nooverlap = False\n",
    "        \n",
    "        \n",
    "        if self.copypaste:\n",
    "            \n",
    "            if self.copy_level == 'random':\n",
    "                dict_ = self.insufficient_class_alldict\n",
    "                \n",
    "                if random.random() > 0.5:\n",
    "                    \n",
    "                    print('Copy Paste !')\n",
    "                    \n",
    "                    copypaste_result = copypaste_candidate_instance(image, mask_instance, mask_class, \n",
    "                                                                 class1_rate, class2_rate, class3_rate, \n",
    "                                                                 class4_rate, class5_rate, class6_rate, dict_, \n",
    "                                                                 resize_rate, self.nooverlap)\n",
    "\n",
    "                    image = copypaste_result['pasted_image']\n",
    "                    mask_instance = copypaste_result['pasted_mask_instance']\n",
    "                    mask_class = copypaste_result['pasted_mask_class']\n",
    "              \n",
    "            \n",
    "            elif self.copy_level == 'source':\n",
    "                \n",
    "                if source == 'consep':\n",
    "                    dict_ = self.insufficient_class_alldict_consep\n",
    "                    \n",
    "                if source == 'crag':\n",
    "                    dict_ = self.insufficient_class_alldict_crag            \n",
    "                    \n",
    "                if source == 'dpath':\n",
    "                    dict_ = self.insufficient_class_alldict_dpath          \n",
    "                    \n",
    "                if source == 'glas':\n",
    "                    dict_ = self.insufficient_class_alldict_glas\n",
    "                    \n",
    "                if source == 'pannuke':\n",
    "                    dict_ = self.insufficient_class_alldict_pannuke                    \n",
    "                \n",
    "                if random.random() > 0.5:\n",
    "                    \n",
    "                    print('Copy Paste !')\n",
    "                    \n",
    "                    copypaste_result = copypaste_candidate_instance(image, mask_instance, mask_class, \n",
    "                                                                 class1_rate, class2_rate, class3_rate, \n",
    "                                                                 class4_rate, class5_rate, class6_rate, dict_, \n",
    "                                                                 resize_rate, self.nooverlap)\n",
    "\n",
    "                    image = copypaste_result['pasted_image']\n",
    "                    mask_instance = copypaste_result['pasted_mask_instance']\n",
    "                    mask_class = copypaste_result['pasted_mask_class']\n",
    "                    \n",
    "            else:\n",
    "                pass\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                                      \n",
    "                        \n",
    "        if self.transform:\n",
    "            \n",
    "            image = A.ColorJitter(brightness=0.3, contrast=0.4, saturation=0.2, hue=0.2, p=0.5)(image=image)['image']\n",
    "\n",
    "            image = A.OneOf([\n",
    "                             A.GaussianBlur(blur_limit=(1, 3), p=1),\n",
    "                             A.MedianBlur(blur_limit=3, p=1),\n",
    "                             A.GaussNoise (var_limit=(10.0, 50.0), p=1)\n",
    "                             ], p=0.5)(image=image)['image']\n",
    "            \n",
    "            \n",
    "            output = A.Compose([\n",
    "                A.ShiftScaleRotate(shift_limit=0, scale_limit=0, rotate_limit=360, interpolation=0, border_mode=4, p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.CoarseDropout(max_holes=4, max_height=40, max_width=40, \n",
    "                                min_holes=2, min_height=20, min_width=20, p=0.5)],\n",
    "                #A.RandomRotate90(90, p=0.5)],\n",
    "                additional_targets={'mask1' : 'image',\n",
    "                                    'mask2' : 'image'})(image=image.astype('uint8'), \n",
    "                                                        mask1=mask_class.astype('uint8'),\n",
    "                                                        mask2=mask_instance.astype('uint8'))            \n",
    "            \n",
    "            \n",
    "            \n",
    "            image = output['image']\n",
    "            mask = output['mask1']\n",
    "            mask_instance = output['mask2']            \n",
    "            \n",
    "            mask_instance = remap_label(mask_instance)\n",
    "            hv_map = gen_targets(mask_instance, (256, 256))['hv_map']\n",
    "\n",
    "\n",
    "            image = transforms.ToTensor()(image)\n",
    "            #image = cropping_center_torch(image, crop_shape=(224, 224), batch=False)\n",
    "            \n",
    "            mask = torch.from_numpy(mask).unsqueeze(0)\n",
    "            mask_instance = torch.from_numpy(mask_instance).unsqueeze(0)\n",
    "            #mask = cropping_center_torch(mask, crop_shape=(224, 224), batch=False)\n",
    "            \n",
    "            hv_map = transforms.ToTensor()(hv_map)\n",
    "            #hv_map = cropping_center_torch(hv_map, crop_shape=(224, 224), batch=False)\n",
    "        \n",
    "        \n",
    "    \n",
    "            return {\"original\" : original, \"image\": image, \"mask\": mask, \"mask_instance\" : mask_instance, 'hv_map' : hv_map, \"mask_class_original\" : mask_class_original}\n",
    "\n",
    "        \n",
    "\n",
    "        else:\n",
    "\n",
    "            image_hflip = A.HorizontalFlip(p=1)(image=image)['image']\n",
    "            image_hflip = transforms.ToTensor()(image_hflip)\n",
    "            #image_hflip = cropping_center_torch(image_hflip, crop_shape=(224, 224), batch=False)\n",
    "            \n",
    "            image_vflip = A.VerticalFlip(p=1)(image=image)['image']\n",
    "            image_vflip = transforms.ToTensor()(image_vflip)\n",
    "            #image_vflip = cropping_center_torch(image_vflip, crop_shape=(224, 224), batch=False)\n",
    "            \n",
    "            image = transforms.ToTensor()(image)\n",
    "            #image = cropping_center_torch(image, crop_shape=(224, 224), batch=False)\n",
    "            \n",
    "            mask = torch.from_numpy(mask_class).unsqueeze(0)\n",
    "            #mask = cropping_center_torch(mask, crop_shape=(224, 224), batch=False)\n",
    "            \n",
    "            hv_map = gen_targets(mask_instance, (256, 256))['hv_map']\n",
    "            hv_map = transforms.ToTensor()(hv_map)\n",
    "            #hv_map = cropping_center_torch(hv_map, crop_shape=(224, 224), batch=False)\n",
    "            \n",
    "            return {\"original\" : original, \"image\": image, \"mask\": mask, 'hv_map' : hv_map, \"image_hflip\" : image_hflip, \"image_vflip\" : image_vflip,  'mask_instance' : mask_instance,  \"mask_class_original\" : mask_class_original}  \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "year = datetime.today().year\n",
    "month = datetime.today().month\n",
    "day = datetime.today().day  \n",
    "\n",
    "today = str(year) + str(month) + str(day)        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "gamma = 1\n",
    "\n",
    "run_info = '-'.format(today, gamma)\n",
    "\n",
    "if not os.path.exists('checkpoint/{}'.format(run_info)):\n",
    "    os.mkdir('checkpoint/{}'.format(run_info))\n",
    "\n",
    "log = logging.getLogger('staining_log')\n",
    "log.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "fileHandler = logging.FileHandler('checkpoint/{}/log.txt'.format(run_info))\n",
    "streamHandler = logging.StreamHandler()\n",
    "fileHandler.setFormatter(formatter)\n",
    "streamHandler.setFormatter(formatter)\n",
    "#\n",
    "log.addHandler(fileHandler)\n",
    "log.addHandler(streamHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e425d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2696a611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e428c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.load('final_data/train_imgs.npy')\n",
    "train_masks = np.load('final_data/train_anns.npy')\n",
    "\n",
    "test_images = np.load('final_data/valid_imgs.npy')\n",
    "test_masks = np.load('final_data/valid_anns.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e73ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5efb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f4a5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ConicDataset(train_images, train_masks, None, None, transform=True, copypaste=False, copy_level = None)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, num_workers=12, shuffle=True)\n",
    "\n",
    "test_dataset = ConicDataset(test_images, test_masks, None, None, transform=False, copypaste=False, copy_level = None)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, num_workers=12, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fd72acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_dataset[0]#['image'].permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0c7ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = temp['image'].permute(1, 2, 0)\n",
    "mask = temp['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a85635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3be24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
